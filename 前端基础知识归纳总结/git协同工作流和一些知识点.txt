#  20 | Git协同工作流，你该怎么选？



陈皓 2017-12-07





与传统的代码版本管理工具相比，Git 有很多的优势，因而越来越成为程序员喜欢的版本管理工具。我觉得，Git 这个代码版本管理工具最大的优势有以下几个。

- Git 是一个分布式的版本管理工具，而且可以是单机版的，所以，你在没有网络的时候同样可以提交（commit）代码。对于我们来说，这意味着在出差途中或是没有网络的环境中依然可以工作写代码。

  这是不是听起来有点不对？一方面，以后你再也不能以“没有网络”作为不能工作的借口了。另一方面，没有网络意味着没有 Google 和 StackOverflow，光有个本地的 Git 我也一样不能写代码啊……（哈哈。好吧，这已经超出了 Git 这个技术的范畴了，这里就不讨论了）

- Git 从一个分支向另一个分支合并代码的时候，会把要合并的分支上的所有提交一个一个应用到被合并的分支上，合并后也能看得到整个代码的变更记录。而其他的版本管理工具则不能。

- Git 切换分支的时候通常很快。不像其他版本管理器，每个分支一份拷贝。

- Git 有很多非常有用的命令，让你可以很方便地工作。

比如我很喜欢的`git stash`命令，可以把当前没有完成的事先暂存一下，然后去忙别的事。`git cherry-pick`命令可以让你有选择地合并提交。`git add -p`可以让你挑选改动提交，`git grep $regexp $(git rev-list --all)`可以用来在所有的提交中找代码。因为都是本地操作，所以你会觉得速度飞快。

除此之外，由 Git 衍生出来的 GitHub/GitLab 可以帮你很好地管理编程工作，比如 wiki、fork、pull request、issue……集成了与编程相关的工作，让人觉得这不是一个冷冰冰的工具，而真正和我们的日常工作发生了很好的交互。

GitHub/GitLab 这样工具的出现，让我们的工作可以呈现在一个工作平台上，并以此来规范整个团队的工作，这才正是 Git 这个版本管理工具成功的原因。

今天，我们不讲 Git 是怎么用的，因为互联网上有太多的文章和书了。而且，如果你还不会用 Git 的话，那么我觉得你已经严重落后于这个时代了。在这篇文章中，我想讲一下 Git 的协同工作流，因为我看到很多团队在使用 Git 时，并没有用好。

注意，因为 Git 是一个分布式的代码管理器，所以，是分布式就会出现数据不一致的情况，因此，我们需要一个协同工作流来让工作变得高效，同时可以有效地让代码具有更好的一致性。

说到一致性，就是每个人手里的开发代码，还有测试和生产线上的代码，要有一个比较好的一致性的管理和协同方法。这就是 Git 协同工作流需要解决的问题。

目前来说，你可能以为我想说的是 GitFlow 工作流。恭喜你猜对了。但是，我想说的是，GitFlow 工作流太过复杂，我并不觉得 GitFlow 工作流是一个好的工作流。如果你的团队在用这种工作流开发软件，我相信你的感觉一定是糟透了。

所以，我的这篇文章会对比一些比较主流的协同工作流，然后，再抨击一下 GitFlow 工作流。

# 中心式协同工作流

首先，我们先说明一下，Git 是可以像 SVN 这样的中心工作流一样工作的。我相信很多程序员都是在采用这样的工作方式。

这个过程一般是下面这个样子的。

1. 从服务器上做`git pull origin master`把代码同步下来。
2. 改完后，`git commit`到本地仓库中。
3. 然后`git push origin master`到远程仓库中，这样其他同学就可以得到你的代码了。

如果在第 3 步发现 push 失败，因为别人已经提交了，那么你需要先把服务器上的代码给 pull 下来，为了避免有 merge 动作，你可以使用 `git pull --rebase` 。这样就可以把服务器上的提交直接合并到你的代码中，对此，Git 的操作是这样的。

1. 先把你本地提交的代码放到一边。
2. 然后把服务器上的改动下载下来。
3. 然后在本地把你之前的改动再重新一个一个地做 commit，直到全部成功。

如下图所示。Git 会把 Origin/Master 的远程分支下载下来（紫色的），然后把本地的 Master 分支上的改动一个一个地提交上去（蓝色的）。









如果有冲突，那么你要先解决冲突，然后做 `git rebase --continue` 。如下图所示，git 在做 pull --rebase 时，会一个一个地应用（apply）本地提交的代码，如果有冲突就会停下来，等你解决冲突。









# 功能分支协同工作流

上面的那种方式有一个问题，就是大家都在一个主干上开发程序，对于小团队或是小项目你可以这么干，但是对比较大的项目或是人比较多的团队，这么干就会有很多问题。

最大的问题就是代码可能干扰太严重。尤其是，我们想安安静静地开发一个功能时，我们想把各个功能的代码变动隔离开来，同时各个功能又会有多个开发人员在开发。

这时，我们不想让各个功能的开发人员都在 Master 分支上共享他们的代码。我们想要的协同方式是这样的：同时开发一个功能的开发人员可以分享各自的代码，但是不会把代码分享给开发其他功能的开发人员，直到整个功能开发完毕后，才会分享给其他的开发人员（也就是进入主干分支）。

因此，我们引入“功能分支”。这个协同工作流的开发过程如下。

1. 首先使用 `git checkout -b new-feature` 创建 “new-feature”分支。
2. 然后共同开发这个功能的程序员就在这个分支上工作，进行 add、commit 等操作。
3. 然后通过 `git push -u origin new-feature` 把分支代码 push 到服务器上。
4. 其他程序员可以通过`git pull --rebase`来拿到最新的这个分支的代码。
5. 最后通过 Pull Request 的方式做完 Code Review 后合并到 Master 分支上。









就像上面这个图显示的一样，紫色的分支就是功能分支，合并后就会像上面这个样子。

我们可以看到，其实，这种开发也是以服务器为中心的开发，还不是 Git 分布式开发，它只不过是用分支来完成代码改动的隔离。

另外，我想提醒一下，为什么会叫“功能分支”，而不是“项目分支”？因为 Git 的最佳实践希望大家在开发的过程中，快速提交，快速合并，快速完成。这样可以少很多冲突的事，所以叫功能分支。

传统的项目分支开得太久，时间越长就越合不回去。这种玩法其实就是让我们把一个大项目切分成若干个小项目来执行（最好是一个小功能一个项目）。这样才是互联网式的快速迭代式的开发流程。

# GitFlow 协同工作流

在真实的生产过程中，前面的协同工作流还是不能满足工作的要求。这主要因为我们的生产过程是比较复杂的，软件生产中会有各式各样的问题，并要面对不同的环境。我们要在不停地开发新代码的同时，维护线上的代码，于是，就有了下面这些需求。

1. 希望有一个分支是非常干净的，上面是可以发布的代码，上面的改动永远都是可以发布到生产环境中的。这个分支上不能有中间开发过程中不可以上生产线的代码提交。
2. 希望当代码达到可以上线的状态时，也就是在 alpha/beta release 时，在测试和交付的过程中，依然可以开发下一个版本的代码。
3. 最后，对于已经发布的代码，也会有一些 Bug-fix 的改动，不会将正在开发的代码提交到生产线上去。

你看，面对这些需求，前面的那些协同方式就都不行了。因为我们不仅是要在整个团队中共享代码，我们要的更是管理好不同环境下的代码不互相干扰。说得技术一点儿就是，要管理好代码与环境的一致性。

为了解决这些问题，GitFlow 协同工作流就出来了。

GitFlow 协同工作流是由 Vincent Driessen 于 2010 年在 A successful Git branching model 这篇文章介绍给世人的。

这个协同工作流的核心思想如下图所示。









整个代码库中一共有五种分支。

- Master 分支。也就是主干分支，用作发布环境，上面的每一次提交都是可以发布的。
- Feature 分支。也就是功能分支，用于开发功能，其对应的是开发环境。
- Developer 分支。是开发分支，一旦功能开发完成，就向 Developer 分支合并，合并完成后，删除功能分支。这个分支对应的是集成测试环境。
- Release 分支。当 Developer 分支测试达到可以发布状态时，开出一个 Release 分支来，然后做发布前的准备工作。这个分支对应的是预发环境。之所以需要这个 Release 分支，是我们的开发可以继续向前，不会因为要发布而被 block 住而不能提交。

一旦 Release 分支上的代码达到可以上线的状态，那么需要把 Release 分支向 Master 分支和 Developer 分支同时合并，以保证代码的一致性。然后再把 Release 分支删除掉。

- Hotfix 分支。是用于处理生产线上代码的 Bug-fix，每个线上代码的 Bug-fix 都需要开一个 Hotfix 分支，完成后，向 Developer 分支和 Master 分支上合并。合并完成后，删除 Hotfix 分支。

这就是整个 GitFlow 协同工作流的工作过程。我们可以看到：

1. 我们需要长期维护 Master 和 Developer 两个分支。
2. 这其中的方式还是有一定复杂度的，尤其是 Release 和 Hotfix 分支需要同时向两个分支作合并。所以，如果没有一个好的工具来支撑的话，这会因为我们可能会忘了做一些操作而导致代码不一致。
3. GitFlow 协同虽然工作流比较重。但是它几乎可以应对所有公司的各种开发流程，包括瀑布模型，或是快速迭代模型。

# GitHub/GitLab 协同工作流

## GitFlow 的问题

对于 GitFlow 来说，虽然可以解决我们的问题，但是也有很多问题。在 GitFlow 流行了一段时间后，圈内出现了一些不同的声音。参看下面两篇吐槽文章。

其中有个问题就是因为分支太多，所以会出现 git log 混乱的局面。具体来说，主要是 git-flow 使用`git merge --no-ff`来合并分支，在 git-flow 这样多个分支的环境下会让你的分支管理的 log 变得很难看。如下所示，左边是使用Cno-ff 参数在多个分支下的问题。









所谓`--no-ff`参数的意思是`――no fast forward`的意思。也就是说，合并的方法不要把这个分支的提交以前置合并的方式，而是留下一个 merge 的提交。这是把双刃剑，我们希望我们的`--no-ff`能像右边那样，而不是像左边那样。

对此的建议是：只有 feature 合并到 developer 分支时，使用Cno-ff 参数，其他的合并都不使用`--no-ff`参数来做合并。

另外，还有一个问题就是，在开发得足够快的时候，你会觉得同时维护 Master 和 Developer 两个分支是一件很无聊的事，因为这两个分支在大多数情况下都是一样的。包括 Release 分支，你会觉得创建的这些分支太无聊。

而你的整个开发过程也会因为这么复杂的管理变得非常复杂。尤其当你想回滚某些人的提交时，你就会发现这事似乎有点儿不好干了。而且在工作过程中，你会来来回回地切换工作的分支，有时候一不小心没有切换，就提交到了不正确的分支上，你还要回滚和重新提交，等等。

GitLab 一开始是 GitFlow 的坚定支持者，后来因为这些吐槽，以及 Hacker News 和 Reddit 上大量的讨论，GitLab 也开始不玩了。他们写了[一篇 blog](https://app.yinxiang.com/OutboundRedirect.action?dest=https%3A%2F%2Fabout.gitlab.com%2F2014%2F09%2F29%2Fgitlab-flow%2F)来创造了一个新的 Workflow――GitLab Flow，这个 GitLab Flow 是基于 GitHub Flow 来做的（参看：[ GitHub Flow](http://scottchacon.com/2011/08/31/github-flow.html) ）。

## GitHub Flow

所谓 GitHub Flow，其实也叫 Forking flow，也就是 GitHub 上的那个开发方式。

1. 每个开发人员都把“官方库”的代码 fork 到自己的代码仓库中。
2. 然后，开发人员在自己的代码仓库中做开发，想干啥干啥。
3. 因此，开发人员的代码库中，需要配两个远程仓库，一个是自己的库，一个是官方库（用户的库用于提交代码改动，官方库用于同步代码）。
4. 然后在本地建“功能分支”，在这个分支上做代码开发。
5. 这个功能分支被 push 到开发人员自己的代码仓库中。
6. 然后，向“官方库”发起 pull request，并做 Code Review。
7. 一旦通过，就向官方库进行合并。

这就是 GitHub 的工作流程。

如果你有“官方库”的权限，那么就可以直接在“官方库”中建功能分支开发，然后提交 pull request。通过 Code Review 后，合并进 Master 分支，而 Master 一旦有代码被合并就可以马上 release。

这是一种非常 Geek 的玩法。这需要一个自动化的 CI/CD 工具做辅助。是的，CI/CD 应该是开发中的标配了。

## GitLab Flow

然而，GitHub Flow 这种玩法依然会有好多问题，因为其虽然变得很简单，但是没有把我们的代码和我们的运行环境给联系在一起。所以，GitLab 提出了几个优化点。

其中一个是引入环境分支，如下图所示，其包含了预发布（Pre-Production）和生产（Production）分支。









而有些时候，我们还会有不同版本的发布，所以，还需要有各种 release 的分支。如下图所示。Master 分支是一个 roadmap 分支，然后，一旦稳定了就建稳定版的分支，如 2.3.stable 分支和 2.4.stable 分支，其中可以 cherry-pick master 分支上的一些改动过去。









这样也就解决了两个问题：

- 环境和代码分支对应的问题；
- 版本和代码分支对应的问题。

老实说，对于互联网公司来说，环境和代码分支对应这个事，只要有个比较好的 CI/CD 生产线，这种环境分支应该也是没有必要的。而对于版本和代码分支的问题，我觉得这应该是有意义的，但是，最好不要维护太多的版本，版本应该是短暂的，等新的版本发布时，老的版本就应该删除掉了。

# 协同工作流的本质

对于上面这些各式各样的工作流的比较和思考，虽然，我个人非常喜欢 GitHub Flow，在必要的时候使用上 GitLab 中的版本或环境分支。不过，我们现实生活中，还是有一些开发工作不是以功能为主，而是以项目为主的。也就是说，项目的改动量可能比较大，时间和周期可能也比较长。

我在想，是否有一种工作流，可以面对我们现实工作中的各种情况。但是，我想这个世界太复杂了，应该不存在一种一招鲜吃遍天的放之四海皆准的银弹方案。所以，我们还要根据自己的实际情况来挑选适合我们的协同工作的方式。

而代码的协同工作流属于 SCM（Software Configuration Management）的范畴，要挑选好适合自己的方式，我们需要知道软件工程配置管理的本质。

根据这么多年来我在各个公司的经历，有互联网的，有金融的，有项目的，有快速迭代的等，我认为团队协同工作的本质不外乎这么几个事儿。

1. 不同的团队能够尽可能地并行开发。
2. 不同软件版本和代码的一致性。
3. 不同环境和代码的一致性。
4. 代码总是会在稳定和不稳定间交替。我们希望生产线上的代码总是能对应到稳定的代码上来。

基本上述的四个事儿，上述的工作流大都是在以建立不同的分支，来做到开发并行、代码和环境版本一致，以及稳定的代码。

要选择适合自己的协同工作流，我们就不得不谈一下软件开发的工作模式。

首先，我们知道软件开发的趋势一定是下面这个样子的。

- **以微服务或是 SOA 为架构的方式**。一个大型软件会被拆分成若干个服务，那么，我们的代码应该也会跟着服务拆解成若干个代码仓库。这样一来，我们的每个代码仓库都会变小，于是我们的协同工作流程就会变简单。

  对于每个服务的代码仓库，我们的开发和迭代速度也会变得很快，开发团队也会跟服务一样被拆分成多个小团队。这样一来， GitFlow 这种协同工作流程就非常重了，而 GitHub 这种方式或是功能分支这种方式会更适合我们的开发。

- **以 DevOps 为主的开发流程**。DevOps 关注于 CI/CD，需要我们有自动化的集成测试和持续部署的工具。这样一来，我们的代码发布速度就会大大加快，每一次提交都能很快地被完整地集成测试，并很快地发布到生产线上。

于是，我们就可以使用更简单的协同工作流程，不需要维护多个版本，也不需要关注不同的运行环境，只需要一套代码，就可以了。GitHub Flow 或是功能分支这种方式也更适应这种开发。

你看，如果我们将软件开发升级并简化到 SOA 服务化以及 DevOps 上来，那么协同工作流就会变得非常简单。所以，**协同工作流的本质，并不是怎么玩好代码仓库的分支策略，而是玩好我们的软件架构和软件开发流程**。

当然，服务化和 DevOps 是每个开发团队需要去努力的目标，但就算是这样，也有某些情况我们需要用重的协同工作的模式。比如，整个公司在做一个大的升级项目，这其中会对代码做一个大的调整（很有可能是一次重大的重构）。

这个时候，可能还有一些并行的开发需要做，如一些小功能的优化，一些线上 Bug 的处理，我们可能还需要在生产线上做新旧两个版本的 A/B 测试。在这样的情况下，我们可能会或多或少地使用 GitFlow 协同工作流。

但是，这样的方式不会是常态，是特殊时期，我们不可能隔三差五地对系统做架构或是对代码做大规模的重构。所以，在大多数情况下，我们还是应该选择一个比较轻量的协同工作流，而在特殊时期特例特办。

最后，让我用一句话来结束这篇文章――**与其花时间在 Git 协同工作流上，还不如把时间花在调整软件架构和自动化软件生产和运维流程上来，这才是真正简化协同工作流程的根本**。













## Javascript部分

##### 1.宏任务、微任务与EventLoop

?	微任务：promise、process.nextTick、MutationObserver

?    宏任务：setTimeOut、setInterval、I/O、script

?	同一次事件循环中，微任务永远在宏任务之前执行。每次执行宏任务结束之后都会检查是否有可执行的微任务，有的话执行所有微任务，否则开始新的宏任务。

执行顺序：首先执行script下的任务，遇到同步任务直接执行。遇到宏任务则将其放入宏任务【队列】，遇到微任务则放入微任务【队列】，同步任务执行之后再依次执行微任务队列，最后依次执行宏任务队列，每个宏任务队列产生的微任务都要全部一次执行完才进入下一个宏任务的执行，直到结束。

一旦遇到await就立刻让出线程，阻塞后面的代码，等候之后对于await来说分两种情况：

?		1.promise对象：暂停执行await后面的代码，先执行async外面的同步代码，等着Promise对象fulfilled，然后把resolve的参数作为await表达式的运算结果

?		2.非promise对象：同上，外面的同步代码执行完毕后，再回到async内部，把promise的东西作为await表达式的结果

##### 2.ESC执行环境栈

?	执行栈既是函数在执行时存储调用过程的栈,同样的,采取调用形式进行队列,先进后出的方式

function foo(i) {
  if (i < 0) return;
    console.log('begin:'+ i);
    foo(i - 1);
    console.log('end:' + i);
  }
  foo(2);
  **// 输出:**`
  `**// begin:2**`
  `**// begin:1**`
  `**// begin:0**`
  `**// end:0**`
  `**// end:1**`
  `**// end:2****`

  

##### 3.如何判断一个对象是不是数组类型

?	1.从原型入手，Array.prototype.isPrototypeOf（obj），判断是否在obj的原型链中

?	2.也可以从构造函数入手，obj instanceof Array（typeof是只会返回基本类型）

?	3.typeof arr == "object" && arr.constructor == Array; //先判断是对象再进一步判断

?	4.根据对象的class属性（类属性），跨原型链调用toString()方法。Object.prototype.toString.call([]);

?	5.Array.isArray()方法

##### 4.请求头包含的内容

?	Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,`*/*`;q=0.8     //浏览器支持的请求类型

?	Accept-Encoding: gzip, deflate, sdch   //浏览器能处理的压缩代码

?	Accept-Language: zh-CN,zh;q=0.8,en;q=0.6  //浏览器当前设置语言

?	Connection: keep-alive　　　   // 连接类型，持续连接

?	Content-Length: 29                  //请求参数长度(post新增)

?	Content-Type: application/json;charset=UTF-8   //请求类型

?	Cookie

?	Host: fhs.fdsfj.com               // 请求的地址域名和端口，不包括协议

?	User-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko)Chrome/58.0.3029.96 	Safari/537.36  //浏览器的用户代理信息

?	Upgrade-Insecure-Requests：1  // http 自动升级到https，防止跨域问题但是域名端口都不同的不会提升

?	Origin: http://www.study.com    //请求来源地址，包括协议



##### 5.Javascript有哪几种方法定义函数

?	1.函数表达式；var func = function(arg0, arg1, ... argN) { statements };

?	2.function声明；function functionName(arg0, arg1, ... argN) { statements }

?	3.function构造函数；var function_name = new Function(arg1, arg2, ..., argN, function_body);

?	4.ES6箭头函数

##### 6.TCP/IP协议的三次握手和四次挥手

?	TCP/IP协议分层：应用层、运输层、网络层、网络接口层

?	6个标志域的各个选项功能：

?		1.URG：紧急标志。紧急标志为"1"表明该位有效。

?		2.ACK：确认标志。表明确认编号栏有效。大多数情况下该标志位是置位的。TCP报头内的确认编号栏内包含的确认编号（w+1）为下一个预期的序列编号，同时提示远端系统已经成功接收所有数据。

?		3.PSH：推标志。该标志置位时，接收端不将该数据进行队列处理，而是尽可能快地将数据转由应用处理。在处理Telnet或rlogin等交互模式的连接时，该标志总是置位的。

?		4.RST：复位标志。用于复位相应的TCP连接。

?		5.SYN：同步标志。表明同步序列编号栏有效。该标志仅在三次握手建立TCP连接时有效。它提示TCP连接的服务端检查序列编号，该序列编号为TCP连接初始端（一般是客户端）的初始序列编号。在这里，可以把TCP序列编号看作是一个范围从0到4，294，967，295的32位计数器。通过TCP连接交换的数据中每一个字节都经过序列编号。在TCP报头中的序列编号栏包括了TCP分段中第一个字节的序列编号。

?		6.FIN：结束标志。

?	TCP三次握手，即建立TCP连接

?		第一次握手：客户端把标志位SYN置为1，随机产生一个值seq=j，并将该数据包发送给服务端。客户端进入SYN_SENT状态，等待服务端确认

?		第二次握手：服务端收到数据包后通过SYN=1可以确定客户端想建立连接。于是把SYN和ACK标志位置为1，然后ack=j+1，再随机产生一个seq=k，将数据包发给客户端。服务端进入SYN_RECV状态

?		第三次握手：客户端收到数据包确认ack是否为j+1;把ACK标志位置为1，并且ack=k+1将数据包发给服务端，服务端检查数据包ack是否为k+1，ACK标志位是否为1，确认即建立连接成功，进入establish状态

?	TCP四次挥手，即终止TCP连接

?		第一次挥手：客户端发送FIN标志给服务端，进入FIN_WAIT_1状态

?		第二次挥手：服务端收到后发送一个ACK给客户端。确认序号为收到序号+1，服务端进入CLOSE_WAIT状态

?		第三次挥手：服务端发送FIN给客户端，用来关闭数据传送。进入LAST_ACK状态

?		第四次挥手：客户端收到FIN后，将ACK置为1，并且确认序号为收到序号+1，服务端进入到CLOSED状态

##### 7.JS中new操作符原理

?	 	var obj = new A();

?		1.创建一个空对象obj；

?		2.将A的原型链赋给对象的_proto _ obj.__proto__ = A.prototype；

?		3.构造函数对象的this指针指向这个对象。A.call(obj)

##### 8.JS中的垃圾回收机制

?	必要性：因为每次创建字符串、数组、对象时都需要动态为他们分配内存来存储，一旦分配都要释放这些内存以便下次在使用，否则会导致内存耗尽系统崩溃。

?	垃圾回收方式：标记清除、计数引用

?	1.标记清除：每个变量进入环境的时候会标记为‘进入环境’，离开环境的时候释放内存。垃圾回收器在运行的时候把标记的变量以及变量引用的变量都删除，回收内存。

?	2.计数引用：当声明了一个变量并且用一个引用类型的值赋给它，那么这个变量的引用次数为1，当包含了对这个值的引用又取了其他值，则引用次数-1。当引用次数为0时回收改变量。缺点：存在内存泄露。比如对象通过各自的属性相互引用的话，就不会有垃圾回收的过程。

##### 9.类的创建和继承

// 定义一个类

?        function Animal(name){

?            // 类的属性

?            this.name = name||'panda';

?            // 实例方法

?            this.sleep = function(){

?                console.log(this.name+'正在睡觉')

?            }

?        }

?        // 原型方法

?        Animal.prototype.eat = function(thing){

?            console.log(this.name+'正在吃'+thing)

?        }

?        Animal.prototype.age = '18';

?        // 原型链继承

?        function dog(){}

?            dog.prototype = new Animal();

?            var dogs = new dog();

?            // 基于原型链的继承，既是父类的实例也是子类的实例，缺点是无法实现多继承

?        // 构造函数继承---使用父类的构造函数来增强子类实例，等于复制父类的实例属性给子类 。缺点是可以实现多继承，但是不能继承原型链上的属性和方法

?        function bird(name){

?            Animal.call(this);

?            this.name = name||'cuicy';  

?            this.sing = function(){

?                console.log(this.name+' is singing!')

?            }

?        }

?        var birds = new bird();

?        //

?        // 实例继承（为父类实例添加新特性，作为子类实例返回）

?        // 拷贝继承（拷贝父类元素上的属性和方法）

?        // 组合继承（构造继承+原型链继承），继承父类的属性并保留传参的优点，通过父类实例作为子类原型，实现函数复用，缺点是调用了两次父类构造函数，生成了两份实例

?        function cat(name){

?            Animal.call(this);

?            this.name = name||'tom'

?        }

?        cat.prototype = new Animal();

?		//construtor属性返回对创建此对象的数组函数的引用

?        cat.prototype.constructor = cat;

?        var cats = new cat();

?        // 寄生组合继承-通过寄生方式，砍掉父类的实例属性，在调用两次父类的构造的时候，就不会初始化两份实例属性方法,较为推荐

?        function snake(){

?            Animal.call(this);

?            this.name = 'snake';

?        }

?        (function(){

?            // 创建一个没有实例方法的类

?           var Super =function(){};

?           Super.prototype = Animal.prototype;

?           snake.prototype = new Super()

?        })();

?        var snakes = new snake();

##### 10.事件流

?	描述的是指从页面中接收事件的顺序,也可理解为事件在页面中传播的顺序。包含三个阶段：事件捕获阶段、处于目标阶段、事件冒泡阶段。

?	事件处理程序：1.HTML事件处理程序；2.DOM0级事件处理程序；3.DOM2级事件处理程序；4.IE事件处理程序；5.跨浏览器的事件处理程序

##### 11.eval的作用-----将对应的字符串解析成js执行

##### 12.websocket的实现和应用

?	websocket是HTML5的协议，支持持久连接。目的是在客户端和服务端之间建立一个不受限的双向通信的通道。服务器可以在任意时刻发送消息给浏览器。

?	请求格式如下：		

```
GET ws://localhost:3000/ws/chat HTTP/1.1
Host: localhost
Upgrade: websocket
Connection: Upgrade
Origin: http://localhost:3000
Sec-WebSocket-Key: client-random-string
Sec-WebSocket-Version: 13
```

1. GET请求的地址不是类似`/path/`，而是以`ws://`开头的地址；

2. 请求头`Upgrade: websocket`和`Connection: Upgrade`表示这个连接将要被转换为WebSocket连接；

3. `Sec-WebSocket-Key`是用于标识这个连接，并非用于加密数据；

4. `Sec-WebSocket-Version`指定了WebSocket的协议版本。

   如果服务器接受该请求则返回如下相应

```
HTTP/1.1 101 Switching Protocols
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Accept: server-random-string
```

为什么WebSocket连接可以实现全双工通信而HTTP连接不行呢？实际上HTTP协议是建立在TCP协议之上的，TCP协议本身就实现了全双工通信，但是HTTP协议的请求－应答机制限制了全双工通信。WebSocket连接建立以后，其实只是简单规定了一下：接下来，咱们通信就不使用HTTP协议了，直接互相发数据吧。

##### 13.类数组对象：arguments

?	是函数运行时的实参列表。arguments与形参是一一映射的。可以用arguments[n]获取参数，可以用arguments.length直接获取实参个数。属性callee装了当前正在运行的函数。可以用来实现递归（严格模式中被禁止使用）。ES6的rest参数

##### 14.数组的扩展

?	1.扩展运算符。将一个数组转为用逗号分隔的参数序列。

?		应用：克隆数组：const a1=[...a2] = a1;合并数组：[...arr1,...arr2,...arr3];与解构赋值结合，用于生成数组：const[first,...rest] = [1,2,3,4,5]，只能放在参数最后一位；字符串转为数组：[...'hello']；定义了遍历器（Iterator）接口的对象用扩展运算符转为真正的数组；map和set结构，generator函数

2.Array.from()。将两类对象转为真正的数组：类数组（array-like）对象和可遍历（iterable）对象。包括Set和Map

3.Array.of()。用于将一组值转换为数组。可用模拟实现 function Arrayof(){ return [].slice.call(arguments)}

4.copyWithin()。从指定位置的成员复制到其他位置（会覆盖原有成员）

?	Array.prototype.copyWithin(target, start = 0, end = this.length)

?	target（必需）开始替换位置，如果为负值，则是倒数。

?	start 从该位置开始读取数据，默认为0.如果是负值，表示从末尾开始计算

5.find()和findIndex()：这两个方法都可以接受第二个参数，用来绑定回调函数的this对象

?	find方法找出第一个符合条件的数组成员。find方法的回调函数接受三个参数，依次为当前的值、当前的位置和原数组。

?	findIndex与find方法类似，返回第一个符合条件的数组成员的位置，所有都不符合条件则返回-1。

6.数组实例的fill()。使用给定值，填充一个数组。接受3个参数，依次为填充的值，填充起始位置和结束位置。如果填充的类型为对象，那么被赋值的是同一个内存地址的对象，而不是深拷贝对象。

7.数组实例的entries()，keys()和values()---用于遍历数组，都返回一个遍历器对象，可以用for...of循环遍历，keys()是对键名的遍历、values()是对键值的遍历、entries()是对键值对的遍历。

8.数组实例的includes()-----返回一个布尔值，是否包含给定的值。接受第二个参数，表示搜索的起始位置，默认为0，如果为负数，则表示倒数的位置，如果大于数组长度则会重置为从0开始。

9.数组实例的flat()，flatMap()---将嵌套的数组拉平，变成一维数组，返回一个新数组，对原数据没有影响。

?	flat()默认只会拉平一层，需要拉平几层参数就填几，可以用Infinity关键字作为参数，不管多少层嵌套都要转成一维数组。如果原数组有空位则会跳过空位。

?	flatMap()对原数组的每个成员执行一个函数。只能展开一层数组。相当于执行map()然后对返回值组成的数组执行flat()方法。还可以有第二个参数，用来绑定遍历函数里面的this。

10.数组的空位---有些会跳过空位，有些将空位视为undefined。

##### 15.属性的遍历

?	（1）for...in：循环遍历对象自身的和继承的可枚举属性（不含Symbol属性）

?	（2）Object.keys（obj）：返回一个数组，包括对象自身的（不含继承的）所有可枚举属性（不含Symbol属性）的键名

?	（3）Object.getOwnPropertyNames（obj）：返回一个数组，包含对象自身的所有属性（不含 Symbol 属性，但是包括不可枚举属性）的键名。

?	（4）Object.getOwnPropertySymbols（obj）：返回一个数组，包含对象自身的所有 Symbol 属性的键名。

?	（5）Reflect.ownKeys(obj)：返回一个数组，包含对象自身的所有键名，不管键名是 Symbol 或字符串，也不管是否可枚举。

##### 	16.Set和Map数据结构

?	（1）Set，类似于数组，但是成员的值是唯一不重复的。

?				[...new Set(array)]---去除数组的重复成员；[...new Set('arraaa')].join('')---去除字符串里面的重复字符。

?				Set结构的实例有以下属性：Set.protoType.constructor：构造函数；Set.prototype.size：返回Set实例的成员总数；Set.prototype.add（value）：添加某个值，返回set结构本身；Set.prototype.delete（value）：删除某个值，返回一个布尔值表示删除是否成功；Set.prototype.has（value）：返回一个布尔值，表示该值是否为Set的成员；Set.prototype.clear（）：清除所有成员，没有返回值。

Set结构的实例有4个遍历方法：Set.prototype.keys（）：返回键名的遍历器；Set.prototype.values（）：返回键值的遍历器；Set.prototype.entries：返回键值对的遍历器；Set.prototype.forEach（）：使用回调函数遍历每个成员



?		





?	






apply和call，以及bind

作用：改变函数运行时this的指向

深克隆



## HTML和CSS部分

##### 1.box-sizing的应用场景

?	浏览器对于一些表单或者按钮的边框的padding和border会存在不一致的情况，比如一个表单中，把输入框和提交按钮宽度都设置为100%，会出现长度不一致的情况；还有三个长度一样的div，给某个div设置了padding之后，这个div的长度扩展了，这个时候就可以将box-sizing设置为border-box，宽度就能保持一致，前提是设置的padding值不超过这个div的宽高值，不然还是会超出。box-sizing：content-box（默认）/border-box/inherit

##### 2.强缓存和协商缓存

?	1.强缓存，指浏览器取请求某个文件的时候，服务端就在response header里面对该文件做了缓存配置，缓存的时间、类型都有服务端控制。cache-control：max-age=xxx（过期时间），public（客户端和代理服务端都缓存），private（只在服务端缓存），immutable（不可改变的）、no-cache（协商缓存）、no-store（不缓存）

?	2.协商缓存，设置协商缓存需要设置response header里面的设置，etag（类似于hash值，唯一，文件更改则发生变化），last-modified（最后修改时间）。触发条件：cache-control的值为no-cache，或者max-age过期了

?	怎么设置强缓存与协商缓存？

?	1.后端服务器如nodejs:res.setHeader(etag:'3hk4h4h-sjfk')；2.ngnix配置；

##### 3.跨域的实现方式

?	1.JSONP

?		利用浏览器对script资源引用没有同源限制，通过动态插入一个script标签，当资源加载到页面后会立即执行的原理来实现跨域的。jsonp是一种非正式传输协议，该协议允许用户传递callback或一开始就定义一个回调方法，参数给服务端，然后服务端发挥数据时会将这个callback参数作为函数名来包裹住JSON数据，这样客户端就可以随意定制自己的函数来自动处理返回的数据了。只支持get请求。

?	



?	

?	

?	








